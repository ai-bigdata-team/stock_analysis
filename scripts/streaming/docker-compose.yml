version: '3'

services:
  # ----------------------------
  # SPARK CLUSTER
  # ----------------------------
  spark-master:
    image: apache/spark:3.5.1
    container_name: spark-master
    environment:
      - SPARK_MASTER_HOST=spark-master
    command: ["/bin/bash", "-c", "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master"]
    networks:
      - spark-network
    ports:
      - "8081:8080"
      - "7077:7077"

  spark-worker-driver:
    image: apache/spark:3.5.1
    container_name: spark-worker-driver
    user: root
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
      - HOME=/tmp
    networks:
      - spark-network
    volumes:
      - ./:/opt/spark/work-dir
      - ./.env:/opt/spark/.env
      - ./google-key.json:/opt/spark/google-key.json
      - ./requirements_spark.txt:/opt/spark/requirements_spark.txt
    command: ["/bin/bash", "-c", "pip install -r /opt/spark/requirements_spark.txt ; /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"]
    depends_on:
      - spark-master
    ports:
      - "4040:4040"

  spark-worker-2:
    image: apache/spark:3.5.1
    container_name: spark-worker-2
    user: root
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
      - HOME=/tmp
    networks:
      - spark-network
    depends_on:
      - spark-master
    command: ["/bin/bash", "-c", "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"]

  spark-worker-3:
    image: apache/spark:3.5.1
    container_name: spark-worker-3
    user: root
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
      - HOME=/tmp
    networks:
      - spark-network
    depends_on:
      - spark-master
    command: ["/bin/bash", "-c", "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"]

  # ----------------------------
  # KAFKA (KRaft Mode - No Zookeeper)
  # ----------------------------
  kafka:
    image: apache/kafka:4.1.1
    container_name: kafka
    networks:
      - spark-network
    ports:
      - "9092:9092"
    environment:
      # Cấu hình KRaft (thay thế Zookeeper)
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ----------------------------
  # FLINK CLUSTER
  # ----------------------------
  flink-jobmanager:
    image: flink:2.1.1
    container_name: flink-jobmanager
    ports:
      - "8082:8081" # Map ra host 8082 để tránh trùng với Spark Master (8081)
      - "6123:6123"
    command: jobmanager
    networks:
      - spark-network
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager

  flink-taskmanager:
    image: flink:2.1.1
    container_name: flink-taskmanager
    depends_on:
      - flink-jobmanager
    command: taskmanager
    networks:
      - spark-network
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2

networks:
  spark-network:
    driver: bridge